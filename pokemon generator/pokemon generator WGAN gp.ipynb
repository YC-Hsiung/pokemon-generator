{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def loadpm():\n",
    "    pmimg=[]\n",
    "    idx=1\n",
    "    while True:\n",
    "        idx=str(idx)\n",
    "        imgpath='pics/type/grass/40x40/poke'+idx+'.jpg'\n",
    "        \n",
    "        try:\n",
    "            img=plt.imread(imgpath)\n",
    "        except:\n",
    "            break\n",
    "        if(idx=='1'):\n",
    "            pmimg=img.reshape(1,img.shape[0], img.shape[1], 3)\n",
    "        else:\n",
    "            pmimg =np.vstack((pmimg,img.reshape(1,img.shape[0], img.shape[1], 3)))\n",
    "        idx=int(idx)\n",
    "        idx+=1\n",
    "    return pmimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 40, 40, 3)\n"
     ]
    }
   ],
   "source": [
    "pokemon=loadpm()\n",
    "pokemon=(pokemon-127.5)/127.5\n",
    "print((pokemon.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.core.debugger import Tracer\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout,Conv2D,MaxPooling2D,Conv2DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.merge import _Merge\n",
    "\n",
    "class Subtract(_Merge):\n",
    "    def _merge_function(self, inputs):\n",
    "        output = inputs[0]\n",
    "        for i in range(1, len(inputs)):\n",
    "            output = output-inputs[i]\n",
    "        return output\n",
    "class GradNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GradNorm, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        super(GradNorm, self).build(input_shapes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        target, wrt = inputs\n",
    "        grads = K.gradients(target, wrt)\n",
    "        assert len(grads) == 1\n",
    "        grad = grads[0]\n",
    "        return K.sqrt(K.sum(K.batch_flatten(K.square(grad)), axis=1, keepdims=True))\n",
    "\n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        return (input_shapes[1][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self,gen_dim,output_size):\n",
    "        self.network=Sequential()\n",
    "        element=1\n",
    "        for i in output_size:\n",
    "            element*=i\n",
    "            \n",
    "        IsDense=False\n",
    "        if(IsDense):\n",
    "        #Dense\n",
    "            self.network.add(Dense(element//16,input_dim=gen_dim,activation='relu'))\n",
    "            self.network.add(Dense(element//4,activation='relu'))\n",
    "            self.network.add(Dense(element//4,activation='relu'))\n",
    "            self.network.add(Dense(element//1,activation='tanh'))\n",
    "            self.network.add(Reshape(output_size))\n",
    "        else:\n",
    "        #Convolution\n",
    "            self.network.add(Dense(element//16*256,input_dim=gen_dim,activation='relu'))\n",
    "            self.network.add(Reshape((output_size[0]//4,output_size[1]//4,output_size[2]*256)))\n",
    "            self.network.add(Conv2DTranspose(filters=256,kernel_size=(3,3),strides=2,padding='same',activation='relu'))  \n",
    "            self.network.add(Conv2DTranspose(filters=256,kernel_size=(3,3),strides=2,padding='same',activation='relu'))\n",
    "            self.network.add(Conv2DTranspose(filters=3,kernel_size=(5,5),padding='same',activation='tanh'))\n",
    "        self.network.summary()\n",
    "class Discriminator():\n",
    "    #Critic\n",
    "    def __init__(self,input_size):\n",
    "        self.network=Sequential()\n",
    "        element=1\n",
    "        for i in input_size:\n",
    "            element*=i\n",
    "\n",
    "        self.network.add(Conv2D(filters=256,kernel_size=(5,5),padding='same',input_shape=input_size))\n",
    "        self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add(Conv2D(filters=256,kernel_size=(3,3),padding='same'))\n",
    "        self.network.add(LeakyReLU(0.2))\n",
    "        \n",
    "        self.network.add((Flatten()))\n",
    "        self.network.add(Dropout(0.2))\n",
    "        #self.network.add(Dense(50))\n",
    "        self.network.add(Dense(1,activation='linear'))\n",
    "        \n",
    "        self.network.summary()\n",
    "        \n",
    "        \n",
    "        \n",
    "class GAN():\n",
    "    def __init__(self,trainingset,gen_dim):\n",
    "        self.trainshape=trainingset.shape\n",
    "        self.trainingset=trainingset\n",
    "        self.gen_dim=gen_dim\n",
    "        \n",
    "        self.n_discriminator = 5\n",
    "        \n",
    "        self._lambda = 10\n",
    "        optimizer = Adam(lr=0.0001,beta_1=0,beta_2=0.9)#RMSprop(lr=0.00005)\n",
    "        #gen_dis\n",
    "        self.generator=Generator(gen_dim,(trainingset.shape[1],trainingset.shape[2],trainingset.shape[3]))\n",
    "        self.discriminator=Discriminator((trainingset.shape[1],trainingset.shape[2],trainingset.shape[3]))\n",
    "        self.GAN_input=Input((gen_dim,))\n",
    "        self.GAN_output=self.discriminator.network(self.generator.network(self.GAN_input))\n",
    "        self.network=Model(self.GAN_input,self.GAN_output)\n",
    "        self.network.compile(loss=self.wasserstein_loss,optimizer=optimizer)\n",
    "        \n",
    "        #gradient\n",
    "        self.inputshape=self.trainshape[1:]\n",
    "        self.real_input,self.gen_input,self.mixed_input=Input(self.inputshape),Input(self.inputshape),Input(self.inputshape)\n",
    "        \n",
    "        self.sub=Subtract()([self.discriminator.network(self.gen_input),self.discriminator.network(self.real_input)])\n",
    "        self.grad_norm=GradNorm()([self.discriminator.network(self.mixed_input),self.mixed_input])\n",
    "        self.grad=Model([self.gen_input,self.real_input,self.mixed_input],[self.sub,self.grad_norm])\n",
    "        self.grad.compile(optimizer=optimizer,loss=[self.mean_loss,'MSE'],loss_weights=[1,self._lambda])\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    def mean_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_pred)\n",
    "    def train(self,iterations):\n",
    "        #train discriminator\n",
    "        #self.start=0\n",
    "        self.batch_size=20\n",
    "        #self.more_to_stop=0\n",
    "        self.real_label=np.ones((self.batch_size, 1))\n",
    "        self.gen_label=-np.ones((self.batch_size, 1))\n",
    "        for step in range(iterations):\n",
    "        #train discriminator\n",
    "            for i in range(self.n_discriminator):\n",
    "            #prepare img\n",
    "                self.random_gen_vectors=np.random.normal(size=(self.batch_size,self.gen_dim))\n",
    "                self.gen_img=self.generator.network.predict(self.random_gen_vectors)\n",
    "                self.epsilon=np.random.uniform(0,1,size=(self.batch_size,1,1,1))\n",
    "                self.idx=np.random.randint(0,self.trainingset.shape[0],self.batch_size)\n",
    "                self.real_img=self.trainingset[self.idx]\n",
    "                self.mixed=self.epsilon*self.real_img+(1-self.epsilon)*self.gen_img\n",
    "                \n",
    "        \n",
    "                #self.labels -= 0.1 * np.random.rand(self.labels.shape[0],self.labels.shape[1])\n",
    "                self.discriminator.network.trainable = True\n",
    "                self.d_loss = self.grad.train_on_batch([self.gen_img,self.real_img,self.mixed],[np.ones((self.batch_size,1)),np.ones((self.batch_size,1))])\n",
    "                \n",
    "                \n",
    "        #train generator\n",
    "            self.discriminator.network.trainable = False\n",
    "            self.random_gen_vector=np.random.normal(size=(self.batch_size,self.gen_dim))\n",
    "            self.g_loss=self.network.train_on_batch(self.random_gen_vector,self.gen_label)\n",
    "            print('iter:%d,d_loss=%f,g_loss=%f'%(step,self.d_loss[0],self.g_loss))\n",
    "            if step%50==0:\n",
    "                #save image\n",
    "                random_vector=np.random.normal(size=(25,self.gen_dim))\n",
    "                images=self.generator.network.predict(random_vector)\n",
    "                images=(images+1)*127.5\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                for i in range(images.shape[0]):\n",
    "                    plt.subplot(5,5,i+1)\n",
    "                    image = images[i, :, :, :]\n",
    "                    image = np.reshape(image,(self.trainshape[1:]))\n",
    "                    plt.imshow(image.astype(np.uint8))\n",
    "                    plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\"output/poke_%d.png\" % step)\n",
    "                plt.close('all')\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 76800)             1612800   \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 10, 10, 768)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 20, 20, 256)       1769728   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 40, 40, 3)         19203     \n",
      "=================================================================\n",
      "Total params: 3,991,811\n",
      "Trainable params: 3,991,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 40, 40, 256)       19456     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 409600)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 409600)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 409601    \n",
      "=================================================================\n",
      "Total params: 1,019,137\n",
      "Trainable params: 1,019,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0,d_loss=-7.685755,g_loss=-0.033776\n",
      "iter:1,d_loss=-105.952026,g_loss=-1.660573\n",
      "iter:2,d_loss=-123.182800,g_loss=-5.759989\n",
      "iter:3,d_loss=-122.300056,g_loss=-11.145782\n",
      "iter:4,d_loss=-113.054764,g_loss=-20.454748\n",
      "iter:5,d_loss=-101.907097,g_loss=-29.164745\n",
      "iter:6,d_loss=-84.962067,g_loss=-40.724129\n",
      "iter:7,d_loss=-73.001831,g_loss=-51.261951\n",
      "iter:8,d_loss=-60.111969,g_loss=-59.392433\n",
      "iter:9,d_loss=-44.780437,g_loss=-64.621338\n",
      "iter:10,d_loss=-40.434864,g_loss=-63.609154\n",
      "iter:11,d_loss=-34.844349,g_loss=-58.374519\n",
      "iter:12,d_loss=-30.307404,g_loss=-54.642242\n",
      "iter:13,d_loss=-31.538033,g_loss=-51.570984\n",
      "iter:14,d_loss=-31.725334,g_loss=-40.623650\n",
      "iter:15,d_loss=-33.113579,g_loss=-31.119370\n",
      "iter:16,d_loss=-36.499165,g_loss=-21.374039\n",
      "iter:17,d_loss=-39.989807,g_loss=-14.675853\n",
      "iter:18,d_loss=-41.575264,g_loss=-4.431133\n",
      "iter:19,d_loss=-42.323700,g_loss=1.657034\n",
      "iter:20,d_loss=-43.764450,g_loss=3.315390\n",
      "iter:21,d_loss=-49.348030,g_loss=1.186437\n",
      "iter:22,d_loss=-40.832710,g_loss=2.203045\n",
      "iter:23,d_loss=-43.701103,g_loss=-1.587433\n",
      "iter:24,d_loss=-39.611870,g_loss=1.668994\n",
      "iter:25,d_loss=-43.101082,g_loss=-6.647691\n",
      "iter:26,d_loss=-44.916557,g_loss=-8.699286\n",
      "iter:27,d_loss=-44.394608,g_loss=0.141814\n",
      "iter:28,d_loss=-43.391209,g_loss=-8.973614\n",
      "iter:29,d_loss=-39.873692,g_loss=-17.653118\n",
      "iter:30,d_loss=-45.929100,g_loss=-13.820663\n",
      "iter:31,d_loss=-40.881474,g_loss=-12.382764\n",
      "iter:32,d_loss=-43.883808,g_loss=-20.364130\n",
      "iter:33,d_loss=-40.181099,g_loss=-21.683556\n",
      "iter:34,d_loss=-41.668396,g_loss=-31.210617\n",
      "iter:35,d_loss=-35.911789,g_loss=-18.772282\n",
      "iter:36,d_loss=-40.859825,g_loss=-27.578314\n",
      "iter:37,d_loss=-42.469986,g_loss=-22.052658\n",
      "iter:38,d_loss=-40.740944,g_loss=-18.124266\n",
      "iter:39,d_loss=-38.824802,g_loss=-20.276882\n",
      "iter:40,d_loss=-36.627625,g_loss=-28.771500\n",
      "iter:41,d_loss=-37.485451,g_loss=-25.984110\n",
      "iter:42,d_loss=-38.193672,g_loss=-28.586990\n",
      "iter:43,d_loss=-32.941124,g_loss=-27.227066\n",
      "iter:44,d_loss=-37.752129,g_loss=-33.401711\n",
      "iter:45,d_loss=-32.841003,g_loss=-35.976807\n",
      "iter:46,d_loss=-36.879910,g_loss=-26.352692\n",
      "iter:47,d_loss=-32.691566,g_loss=-38.145470\n",
      "iter:48,d_loss=-33.841953,g_loss=-36.220726\n",
      "iter:49,d_loss=-32.737240,g_loss=-28.992498\n",
      "iter:50,d_loss=-30.923592,g_loss=-32.289772\n",
      "iter:51,d_loss=-32.069405,g_loss=-39.938942\n",
      "iter:52,d_loss=-31.104061,g_loss=-35.481579\n",
      "iter:53,d_loss=-33.928261,g_loss=-37.464684\n",
      "iter:54,d_loss=-30.249660,g_loss=-31.840088\n",
      "iter:55,d_loss=-30.758993,g_loss=-42.219097\n",
      "iter:56,d_loss=-28.802860,g_loss=-36.161736\n",
      "iter:57,d_loss=-27.782171,g_loss=-46.686665\n",
      "iter:58,d_loss=-33.156311,g_loss=-33.263279\n",
      "iter:59,d_loss=-29.670860,g_loss=-47.328026\n",
      "iter:60,d_loss=-25.306515,g_loss=-38.034058\n",
      "iter:61,d_loss=-31.199104,g_loss=-33.225674\n",
      "iter:62,d_loss=-25.639666,g_loss=-51.631432\n",
      "iter:63,d_loss=-28.296715,g_loss=-43.186932\n",
      "iter:64,d_loss=-28.053558,g_loss=-37.129196\n",
      "iter:65,d_loss=-23.046139,g_loss=-51.056957\n",
      "iter:66,d_loss=-25.220451,g_loss=-38.334789\n",
      "iter:67,d_loss=-26.302675,g_loss=-44.343803\n",
      "iter:68,d_loss=-25.312210,g_loss=-53.281303\n",
      "iter:69,d_loss=-26.525915,g_loss=-46.488857\n",
      "iter:70,d_loss=-28.827129,g_loss=-40.048153\n",
      "iter:71,d_loss=-23.101702,g_loss=-49.713955\n",
      "iter:72,d_loss=-24.153078,g_loss=-43.272003\n",
      "iter:73,d_loss=-25.460392,g_loss=-41.146168\n",
      "iter:74,d_loss=-25.275211,g_loss=-53.182301\n",
      "iter:75,d_loss=-24.108654,g_loss=-42.109825\n",
      "iter:76,d_loss=-21.408634,g_loss=-44.158276\n",
      "iter:77,d_loss=-20.012985,g_loss=-42.477654\n",
      "iter:78,d_loss=-23.840271,g_loss=-54.869263\n",
      "iter:79,d_loss=-22.933790,g_loss=-41.561897\n",
      "iter:80,d_loss=-24.989788,g_loss=-40.686665\n",
      "iter:81,d_loss=-19.450563,g_loss=-56.640636\n",
      "iter:82,d_loss=-19.981020,g_loss=-51.989483\n",
      "iter:83,d_loss=-21.206482,g_loss=-44.329987\n",
      "iter:84,d_loss=-24.238188,g_loss=-42.344826\n",
      "iter:85,d_loss=-20.731430,g_loss=-51.999134\n",
      "iter:86,d_loss=-20.112339,g_loss=-46.664684\n",
      "iter:87,d_loss=-25.023808,g_loss=-54.863800\n",
      "iter:88,d_loss=-18.660835,g_loss=-51.099350\n",
      "iter:89,d_loss=-19.252586,g_loss=-54.522095\n",
      "iter:90,d_loss=-23.410397,g_loss=-45.476707\n",
      "iter:91,d_loss=-19.028854,g_loss=-46.825676\n",
      "iter:92,d_loss=-19.779140,g_loss=-50.982677\n",
      "iter:93,d_loss=-19.837101,g_loss=-49.300568\n",
      "iter:94,d_loss=-17.930302,g_loss=-52.690960\n",
      "iter:95,d_loss=-18.590395,g_loss=-54.167042\n",
      "iter:96,d_loss=-20.366589,g_loss=-43.068371\n",
      "iter:97,d_loss=-19.969070,g_loss=-59.112701\n",
      "iter:98,d_loss=-18.140148,g_loss=-57.580688\n",
      "iter:99,d_loss=-17.375416,g_loss=-55.776062\n",
      "iter:100,d_loss=-20.720272,g_loss=-44.365101\n",
      "iter:101,d_loss=-17.096451,g_loss=-56.510632\n",
      "iter:102,d_loss=-17.383682,g_loss=-60.694550\n",
      "iter:103,d_loss=-15.537086,g_loss=-53.019676\n",
      "iter:104,d_loss=-15.600541,g_loss=-49.103249\n",
      "iter:105,d_loss=-17.120285,g_loss=-48.557514\n",
      "iter:106,d_loss=-15.166749,g_loss=-56.704346\n",
      "iter:107,d_loss=-15.398434,g_loss=-59.120605\n",
      "iter:108,d_loss=-16.561825,g_loss=-48.386032\n",
      "iter:109,d_loss=-16.185196,g_loss=-52.597363\n",
      "iter:110,d_loss=-18.993153,g_loss=-50.876579\n",
      "iter:111,d_loss=-19.103317,g_loss=-61.115692\n",
      "iter:112,d_loss=-15.804108,g_loss=-53.265430\n",
      "iter:113,d_loss=-16.789373,g_loss=-54.173962\n",
      "iter:114,d_loss=-16.837971,g_loss=-52.778038\n",
      "iter:115,d_loss=-14.913296,g_loss=-58.345825\n",
      "iter:116,d_loss=-15.194708,g_loss=-50.033955\n",
      "iter:117,d_loss=-15.609642,g_loss=-60.775124\n",
      "iter:118,d_loss=-16.175409,g_loss=-50.164959\n",
      "iter:119,d_loss=-15.766529,g_loss=-51.842354\n",
      "iter:120,d_loss=-16.474136,g_loss=-49.566410\n",
      "iter:121,d_loss=-16.156549,g_loss=-67.556160\n",
      "iter:122,d_loss=-16.423498,g_loss=-53.605659\n",
      "iter:123,d_loss=-16.518185,g_loss=-53.937855\n",
      "iter:124,d_loss=-15.708014,g_loss=-62.985138\n",
      "iter:125,d_loss=-17.748598,g_loss=-62.968903\n",
      "iter:126,d_loss=-13.991693,g_loss=-60.202198\n",
      "iter:127,d_loss=-16.872843,g_loss=-68.218971\n",
      "iter:128,d_loss=-18.300568,g_loss=-51.878132\n",
      "iter:129,d_loss=-18.217354,g_loss=-58.514759\n",
      "iter:130,d_loss=-17.011293,g_loss=-74.121399\n",
      "iter:131,d_loss=-16.201466,g_loss=-55.425697\n",
      "iter:132,d_loss=-16.862324,g_loss=-67.822586\n",
      "iter:133,d_loss=-15.959668,g_loss=-71.579605\n",
      "iter:134,d_loss=-15.223203,g_loss=-60.739044\n",
      "iter:135,d_loss=-16.654898,g_loss=-60.606647\n",
      "iter:136,d_loss=-15.346235,g_loss=-63.220715\n",
      "iter:137,d_loss=-15.701267,g_loss=-58.881386\n",
      "iter:138,d_loss=-12.851779,g_loss=-65.758957\n",
      "iter:139,d_loss=-14.941305,g_loss=-64.630875\n",
      "iter:140,d_loss=-15.910088,g_loss=-65.609879\n",
      "iter:141,d_loss=-14.521181,g_loss=-64.844345\n",
      "iter:142,d_loss=-15.590798,g_loss=-67.894852\n",
      "iter:143,d_loss=-14.500243,g_loss=-73.193527\n",
      "iter:144,d_loss=-14.741365,g_loss=-58.262157\n",
      "iter:145,d_loss=-16.172913,g_loss=-67.980240\n",
      "iter:146,d_loss=-13.251377,g_loss=-68.683617\n",
      "iter:147,d_loss=-15.192501,g_loss=-71.011406\n",
      "iter:148,d_loss=-13.909882,g_loss=-70.183273\n",
      "iter:149,d_loss=-15.677278,g_loss=-65.112839\n",
      "iter:150,d_loss=-14.473083,g_loss=-71.140709\n",
      "iter:151,d_loss=-13.850109,g_loss=-72.323456\n",
      "iter:152,d_loss=-13.436881,g_loss=-67.346069\n",
      "iter:153,d_loss=-14.439656,g_loss=-66.637589\n",
      "iter:154,d_loss=-15.129560,g_loss=-77.765587\n",
      "iter:155,d_loss=-14.350601,g_loss=-67.889626\n",
      "iter:156,d_loss=-14.107804,g_loss=-65.154419\n",
      "iter:157,d_loss=-13.831614,g_loss=-74.636330\n",
      "iter:158,d_loss=-15.859156,g_loss=-73.654099\n",
      "iter:159,d_loss=-17.046591,g_loss=-71.820984\n",
      "iter:160,d_loss=-13.575567,g_loss=-77.041992\n",
      "iter:161,d_loss=-14.569405,g_loss=-77.219810\n",
      "iter:162,d_loss=-13.763650,g_loss=-80.162704\n",
      "iter:163,d_loss=-12.646856,g_loss=-73.340256\n",
      "iter:164,d_loss=-13.812056,g_loss=-69.003487\n",
      "iter:165,d_loss=-14.329620,g_loss=-96.113441\n",
      "iter:166,d_loss=-13.473835,g_loss=-78.857681\n",
      "iter:167,d_loss=-14.386209,g_loss=-70.917168\n",
      "iter:168,d_loss=-13.131175,g_loss=-85.808029\n",
      "iter:169,d_loss=-13.076631,g_loss=-96.637589\n",
      "iter:170,d_loss=-13.072357,g_loss=-71.090431\n",
      "iter:171,d_loss=-12.897821,g_loss=-85.834122\n",
      "iter:172,d_loss=-12.931894,g_loss=-96.467781\n",
      "iter:173,d_loss=-12.347156,g_loss=-86.721420\n",
      "iter:174,d_loss=-13.996940,g_loss=-79.068047\n",
      "iter:175,d_loss=-14.121408,g_loss=-96.539322\n",
      "iter:176,d_loss=-14.032700,g_loss=-95.383171\n",
      "iter:177,d_loss=-12.796337,g_loss=-91.303673\n",
      "iter:178,d_loss=-14.037496,g_loss=-85.603271\n",
      "iter:179,d_loss=-12.505018,g_loss=-91.102776\n",
      "iter:180,d_loss=-14.939329,g_loss=-94.951996\n",
      "iter:181,d_loss=-13.057156,g_loss=-91.049507\n",
      "iter:182,d_loss=-14.341528,g_loss=-86.925949\n",
      "iter:183,d_loss=-12.417339,g_loss=-86.576134\n",
      "iter:184,d_loss=-13.419189,g_loss=-81.271080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:185,d_loss=-13.159391,g_loss=-99.633003\n",
      "iter:186,d_loss=-14.057295,g_loss=-87.370880\n",
      "iter:187,d_loss=-13.767578,g_loss=-90.959084\n",
      "iter:188,d_loss=-10.174692,g_loss=-102.519188\n",
      "iter:189,d_loss=-13.309009,g_loss=-85.721642\n",
      "iter:190,d_loss=-13.684922,g_loss=-104.048813\n",
      "iter:191,d_loss=-14.682049,g_loss=-86.088966\n",
      "iter:192,d_loss=-13.149967,g_loss=-102.783005\n",
      "iter:193,d_loss=-12.444973,g_loss=-93.288986\n",
      "iter:194,d_loss=-13.033555,g_loss=-116.398056\n",
      "iter:195,d_loss=-11.860394,g_loss=-106.478195\n",
      "iter:196,d_loss=-11.854500,g_loss=-99.894066\n",
      "iter:197,d_loss=-13.066435,g_loss=-104.168076\n",
      "iter:198,d_loss=-12.270594,g_loss=-109.867874\n",
      "iter:199,d_loss=-13.619677,g_loss=-99.959854\n",
      "iter:200,d_loss=-13.854608,g_loss=-112.190292\n",
      "iter:201,d_loss=-12.673324,g_loss=-111.710915\n",
      "iter:202,d_loss=-13.308568,g_loss=-105.872253\n",
      "iter:203,d_loss=-15.368922,g_loss=-95.341965\n",
      "iter:204,d_loss=-13.429768,g_loss=-146.923187\n",
      "iter:205,d_loss=-14.178229,g_loss=-100.725464\n",
      "iter:206,d_loss=-13.125933,g_loss=-102.282066\n",
      "iter:207,d_loss=-10.840151,g_loss=-126.235023\n",
      "iter:208,d_loss=-13.172467,g_loss=-117.631058\n",
      "iter:209,d_loss=-13.671744,g_loss=-120.295700\n",
      "iter:210,d_loss=-12.511056,g_loss=-135.399765\n",
      "iter:211,d_loss=-13.545528,g_loss=-126.536453\n",
      "iter:212,d_loss=-13.875677,g_loss=-106.742752\n",
      "iter:213,d_loss=-13.599634,g_loss=-126.508774\n",
      "iter:214,d_loss=-12.700421,g_loss=-119.546898\n",
      "iter:215,d_loss=-11.968234,g_loss=-133.445099\n",
      "iter:216,d_loss=-12.696210,g_loss=-109.794479\n",
      "iter:217,d_loss=-14.031416,g_loss=-128.973923\n",
      "iter:218,d_loss=-11.302544,g_loss=-146.920242\n",
      "iter:219,d_loss=-14.577794,g_loss=-116.869705\n",
      "iter:220,d_loss=-12.825026,g_loss=-124.882423\n",
      "iter:221,d_loss=-11.540748,g_loss=-140.129074\n",
      "iter:222,d_loss=-14.560341,g_loss=-126.368713\n",
      "iter:223,d_loss=-12.344625,g_loss=-135.126480\n",
      "iter:224,d_loss=-10.887092,g_loss=-143.031006\n",
      "iter:225,d_loss=-12.522659,g_loss=-139.532928\n",
      "iter:226,d_loss=-10.120226,g_loss=-136.532654\n",
      "iter:227,d_loss=-11.318155,g_loss=-141.566162\n",
      "iter:228,d_loss=-11.818458,g_loss=-128.737335\n",
      "iter:229,d_loss=-12.427795,g_loss=-121.902908\n",
      "iter:230,d_loss=-12.691607,g_loss=-120.614037\n",
      "iter:231,d_loss=-12.286730,g_loss=-144.680084\n",
      "iter:232,d_loss=-11.434756,g_loss=-146.779343\n",
      "iter:233,d_loss=-11.578978,g_loss=-132.302643\n",
      "iter:234,d_loss=-11.407955,g_loss=-129.962402\n",
      "iter:235,d_loss=-12.498256,g_loss=-148.839279\n",
      "iter:236,d_loss=-12.102842,g_loss=-150.673615\n",
      "iter:237,d_loss=-14.408413,g_loss=-120.414810\n",
      "iter:238,d_loss=-11.685783,g_loss=-143.579575\n",
      "iter:239,d_loss=-12.057716,g_loss=-142.418854\n",
      "iter:240,d_loss=-11.841450,g_loss=-144.713776\n",
      "iter:241,d_loss=-12.968985,g_loss=-140.130295\n",
      "iter:242,d_loss=-13.893665,g_loss=-163.664642\n",
      "iter:243,d_loss=-13.944691,g_loss=-148.427322\n",
      "iter:244,d_loss=-13.169321,g_loss=-153.928329\n",
      "iter:245,d_loss=-12.342364,g_loss=-184.882309\n",
      "iter:246,d_loss=-12.467514,g_loss=-155.991379\n",
      "iter:247,d_loss=-10.777426,g_loss=-170.714157\n",
      "iter:248,d_loss=-14.636421,g_loss=-148.984406\n",
      "iter:249,d_loss=-12.705524,g_loss=-176.471527\n",
      "iter:250,d_loss=-12.519166,g_loss=-167.469360\n",
      "iter:251,d_loss=-12.465832,g_loss=-160.887375\n",
      "iter:252,d_loss=-10.933350,g_loss=-189.549057\n",
      "iter:253,d_loss=-13.188182,g_loss=-162.647247\n",
      "iter:254,d_loss=-12.919420,g_loss=-184.240875\n",
      "iter:255,d_loss=-11.575735,g_loss=-176.235214\n",
      "iter:256,d_loss=-14.043694,g_loss=-182.665421\n",
      "iter:257,d_loss=-12.031197,g_loss=-205.087814\n",
      "iter:258,d_loss=-13.039774,g_loss=-180.262405\n",
      "iter:259,d_loss=-12.514219,g_loss=-188.024399\n",
      "iter:260,d_loss=-14.617572,g_loss=-201.944977\n",
      "iter:261,d_loss=-12.019022,g_loss=-188.841965\n",
      "iter:262,d_loss=-12.927820,g_loss=-191.007660\n",
      "iter:263,d_loss=-12.035460,g_loss=-196.421188\n",
      "iter:264,d_loss=-11.891313,g_loss=-188.581940\n",
      "iter:265,d_loss=-12.694583,g_loss=-220.816437\n",
      "iter:266,d_loss=-11.564880,g_loss=-186.655212\n",
      "iter:267,d_loss=-11.653006,g_loss=-197.389465\n",
      "iter:268,d_loss=-12.753325,g_loss=-203.748764\n",
      "iter:269,d_loss=-9.109359,g_loss=-193.328644\n",
      "iter:270,d_loss=-12.332363,g_loss=-228.057571\n",
      "iter:271,d_loss=-12.392303,g_loss=-192.472168\n",
      "iter:272,d_loss=-14.021688,g_loss=-187.469208\n",
      "iter:273,d_loss=-13.145152,g_loss=-207.995331\n",
      "iter:274,d_loss=-11.310207,g_loss=-233.301422\n",
      "iter:275,d_loss=-12.367193,g_loss=-214.663727\n",
      "iter:276,d_loss=-14.200516,g_loss=-200.820282\n",
      "iter:277,d_loss=-12.003241,g_loss=-224.230804\n",
      "iter:278,d_loss=-10.207472,g_loss=-231.777786\n",
      "iter:279,d_loss=-12.226196,g_loss=-207.739899\n",
      "iter:280,d_loss=-10.025894,g_loss=-218.567139\n",
      "iter:281,d_loss=-12.793954,g_loss=-220.547211\n",
      "iter:282,d_loss=-10.913586,g_loss=-245.504318\n",
      "iter:283,d_loss=-12.435303,g_loss=-219.679535\n",
      "iter:284,d_loss=-9.920879,g_loss=-221.453735\n",
      "iter:285,d_loss=-11.468351,g_loss=-239.966461\n",
      "iter:286,d_loss=-11.816128,g_loss=-216.089722\n",
      "iter:287,d_loss=-11.543767,g_loss=-235.592377\n",
      "iter:288,d_loss=-9.323376,g_loss=-227.989182\n",
      "iter:289,d_loss=-12.346671,g_loss=-227.314240\n",
      "iter:290,d_loss=-12.327406,g_loss=-261.367340\n",
      "iter:291,d_loss=-12.202374,g_loss=-234.943390\n",
      "iter:292,d_loss=-11.389299,g_loss=-235.793091\n",
      "iter:293,d_loss=-13.527397,g_loss=-270.062561\n",
      "iter:294,d_loss=-10.935798,g_loss=-284.442688\n",
      "iter:295,d_loss=-12.192946,g_loss=-246.460602\n",
      "iter:296,d_loss=-12.167820,g_loss=-269.746277\n",
      "iter:297,d_loss=-10.648911,g_loss=-278.958191\n",
      "iter:298,d_loss=-11.575058,g_loss=-261.106262\n",
      "iter:299,d_loss=-12.233189,g_loss=-245.978302\n",
      "iter:300,d_loss=-12.007524,g_loss=-256.838531\n",
      "iter:301,d_loss=-9.464292,g_loss=-277.466461\n",
      "iter:302,d_loss=-12.629329,g_loss=-269.736328\n",
      "iter:303,d_loss=-10.550105,g_loss=-275.233582\n",
      "iter:304,d_loss=-11.018142,g_loss=-277.064880\n",
      "iter:305,d_loss=-13.004633,g_loss=-273.296082\n",
      "iter:306,d_loss=-12.132464,g_loss=-266.959442\n",
      "iter:307,d_loss=-13.669050,g_loss=-265.362396\n",
      "iter:308,d_loss=-12.800013,g_loss=-292.996216\n",
      "iter:309,d_loss=-12.191454,g_loss=-255.063934\n",
      "iter:310,d_loss=-10.569096,g_loss=-281.951721\n",
      "iter:311,d_loss=-11.727791,g_loss=-307.483246\n",
      "iter:312,d_loss=-10.888876,g_loss=-306.273682\n",
      "iter:313,d_loss=-12.049668,g_loss=-299.939270\n",
      "iter:314,d_loss=-12.496416,g_loss=-299.512512\n",
      "iter:315,d_loss=-10.193718,g_loss=-299.986572\n",
      "iter:316,d_loss=-7.862567,g_loss=-301.604004\n",
      "iter:317,d_loss=-10.635495,g_loss=-304.079468\n",
      "iter:318,d_loss=-11.650211,g_loss=-341.454041\n",
      "iter:319,d_loss=-9.220881,g_loss=-327.914154\n",
      "iter:320,d_loss=-13.163733,g_loss=-322.350464\n",
      "iter:321,d_loss=-13.354605,g_loss=-307.714813\n",
      "iter:322,d_loss=-11.973745,g_loss=-309.842712\n",
      "iter:323,d_loss=-9.363555,g_loss=-329.776611\n",
      "iter:324,d_loss=-10.833838,g_loss=-334.720123\n",
      "iter:325,d_loss=-10.112095,g_loss=-332.186951\n",
      "iter:326,d_loss=-11.688731,g_loss=-327.037170\n",
      "iter:327,d_loss=-11.399096,g_loss=-332.635101\n",
      "iter:328,d_loss=-12.298711,g_loss=-317.650574\n",
      "iter:329,d_loss=-10.809256,g_loss=-339.530457\n",
      "iter:330,d_loss=-11.044577,g_loss=-330.311218\n",
      "iter:331,d_loss=-11.657780,g_loss=-334.189911\n",
      "iter:332,d_loss=-10.672851,g_loss=-354.534912\n",
      "iter:333,d_loss=-9.983282,g_loss=-354.374023\n",
      "iter:334,d_loss=-12.225592,g_loss=-328.336090\n",
      "iter:335,d_loss=-11.581336,g_loss=-360.640930\n",
      "iter:336,d_loss=-11.679026,g_loss=-346.203461\n",
      "iter:337,d_loss=-12.418424,g_loss=-336.443359\n",
      "iter:338,d_loss=-11.061507,g_loss=-388.811829\n",
      "iter:339,d_loss=-11.896788,g_loss=-359.661041\n",
      "iter:340,d_loss=-12.877004,g_loss=-347.527222\n",
      "iter:341,d_loss=-11.573130,g_loss=-376.776764\n",
      "iter:342,d_loss=-9.761143,g_loss=-391.736908\n",
      "iter:343,d_loss=-12.716654,g_loss=-394.507477\n",
      "iter:344,d_loss=-11.356667,g_loss=-371.380615\n",
      "iter:345,d_loss=-13.335976,g_loss=-419.588531\n",
      "iter:346,d_loss=-11.804481,g_loss=-381.283752\n",
      "iter:347,d_loss=-11.482538,g_loss=-395.408630\n",
      "iter:348,d_loss=-14.995797,g_loss=-385.305023\n",
      "iter:349,d_loss=-11.293118,g_loss=-404.473206\n",
      "iter:350,d_loss=-10.100731,g_loss=-403.911804\n",
      "iter:351,d_loss=-13.177846,g_loss=-392.963806\n",
      "iter:352,d_loss=-12.523890,g_loss=-409.088684\n",
      "iter:353,d_loss=-12.235028,g_loss=-401.833923\n",
      "iter:354,d_loss=-10.852052,g_loss=-406.607483\n",
      "iter:355,d_loss=-11.180725,g_loss=-396.561371\n",
      "iter:356,d_loss=-9.755710,g_loss=-412.528137\n",
      "iter:357,d_loss=-13.741082,g_loss=-399.001617\n",
      "iter:358,d_loss=-7.885018,g_loss=-451.176208\n",
      "iter:359,d_loss=-10.334008,g_loss=-424.067535\n",
      "iter:360,d_loss=-11.168837,g_loss=-448.879730\n",
      "iter:361,d_loss=-10.294933,g_loss=-431.235168\n",
      "iter:362,d_loss=-12.324410,g_loss=-434.412292\n",
      "iter:363,d_loss=-11.492566,g_loss=-441.233582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:364,d_loss=-13.154729,g_loss=-450.831360\n",
      "iter:365,d_loss=-10.599329,g_loss=-435.791901\n",
      "iter:366,d_loss=-12.229684,g_loss=-443.330017\n",
      "iter:367,d_loss=-11.953853,g_loss=-428.148987\n",
      "iter:368,d_loss=-10.294530,g_loss=-428.018158\n",
      "iter:369,d_loss=-9.847290,g_loss=-445.923492\n",
      "iter:370,d_loss=-9.234388,g_loss=-472.755066\n",
      "iter:371,d_loss=-10.584282,g_loss=-461.871979\n",
      "iter:372,d_loss=-11.484734,g_loss=-454.125183\n",
      "iter:373,d_loss=-11.071257,g_loss=-453.649750\n",
      "iter:374,d_loss=-10.783833,g_loss=-461.031433\n",
      "iter:375,d_loss=-11.707830,g_loss=-446.244446\n",
      "iter:376,d_loss=-13.289780,g_loss=-456.269775\n",
      "iter:377,d_loss=-9.604707,g_loss=-472.576172\n",
      "iter:378,d_loss=-11.401791,g_loss=-484.356781\n",
      "iter:379,d_loss=-10.332222,g_loss=-466.062561\n",
      "iter:380,d_loss=-12.062513,g_loss=-454.252441\n",
      "iter:381,d_loss=-12.667760,g_loss=-491.857971\n",
      "iter:382,d_loss=-12.355183,g_loss=-482.356293\n",
      "iter:383,d_loss=-12.407598,g_loss=-470.874451\n",
      "iter:384,d_loss=-10.930805,g_loss=-477.582825\n",
      "iter:385,d_loss=-12.210072,g_loss=-470.125061\n",
      "iter:386,d_loss=-10.715560,g_loss=-478.233154\n",
      "iter:387,d_loss=-10.107634,g_loss=-486.320618\n",
      "iter:388,d_loss=-10.620709,g_loss=-503.649597\n",
      "iter:389,d_loss=-13.151601,g_loss=-479.068756\n",
      "iter:390,d_loss=-11.411297,g_loss=-494.824310\n",
      "iter:391,d_loss=-10.642605,g_loss=-503.633301\n",
      "iter:392,d_loss=-11.719374,g_loss=-487.547546\n",
      "iter:393,d_loss=-9.221641,g_loss=-497.043701\n",
      "iter:394,d_loss=-9.297928,g_loss=-520.442383\n",
      "iter:395,d_loss=-10.170553,g_loss=-505.365143\n",
      "iter:396,d_loss=-11.377339,g_loss=-513.024292\n",
      "iter:397,d_loss=-10.008350,g_loss=-525.655212\n",
      "iter:398,d_loss=-9.686236,g_loss=-518.788513\n",
      "iter:399,d_loss=-7.911073,g_loss=-516.733398\n",
      "iter:400,d_loss=-2.185295,g_loss=-553.375732\n",
      "iter:401,d_loss=-11.315717,g_loss=-502.262115\n",
      "iter:402,d_loss=-10.127135,g_loss=-536.323181\n",
      "iter:403,d_loss=-12.835195,g_loss=-513.724670\n",
      "iter:404,d_loss=-9.596201,g_loss=-536.308716\n",
      "iter:405,d_loss=-9.150701,g_loss=-523.676392\n",
      "iter:406,d_loss=-8.450367,g_loss=-556.763062\n",
      "iter:407,d_loss=-11.896702,g_loss=-520.515320\n",
      "iter:408,d_loss=-11.181343,g_loss=-547.850952\n",
      "iter:409,d_loss=-11.595678,g_loss=-516.987915\n",
      "iter:410,d_loss=-5.651752,g_loss=-538.245605\n",
      "iter:411,d_loss=-8.591059,g_loss=-539.511597\n",
      "iter:412,d_loss=-9.335761,g_loss=-550.779907\n",
      "iter:413,d_loss=-10.626131,g_loss=-541.994141\n",
      "iter:414,d_loss=-9.769136,g_loss=-552.319641\n",
      "iter:415,d_loss=-9.997292,g_loss=-564.150696\n",
      "iter:416,d_loss=-9.570871,g_loss=-565.636047\n",
      "iter:417,d_loss=-7.206329,g_loss=-562.739990\n",
      "iter:418,d_loss=-10.889858,g_loss=-546.245239\n",
      "iter:419,d_loss=-10.421618,g_loss=-587.901062\n",
      "iter:420,d_loss=-11.097347,g_loss=-582.942993\n",
      "iter:421,d_loss=-9.793258,g_loss=-622.350464\n",
      "iter:422,d_loss=-10.354383,g_loss=-589.431824\n",
      "iter:423,d_loss=-10.209768,g_loss=-579.445801\n",
      "iter:424,d_loss=-9.920124,g_loss=-604.100281\n",
      "iter:425,d_loss=-9.945269,g_loss=-601.152710\n",
      "iter:426,d_loss=-9.405339,g_loss=-586.640259\n",
      "iter:427,d_loss=-10.648375,g_loss=-593.574280\n",
      "iter:428,d_loss=-11.953196,g_loss=-604.473022\n",
      "iter:429,d_loss=-9.162264,g_loss=-624.461060\n",
      "iter:430,d_loss=-11.087152,g_loss=-598.379211\n",
      "iter:431,d_loss=-9.793180,g_loss=-636.174744\n",
      "iter:432,d_loss=-9.649046,g_loss=-621.274719\n",
      "iter:433,d_loss=-10.428011,g_loss=-623.069702\n",
      "iter:434,d_loss=-11.472316,g_loss=-625.610229\n",
      "iter:435,d_loss=-0.825038,g_loss=-626.242371\n",
      "iter:436,d_loss=-11.761648,g_loss=-637.862854\n",
      "iter:437,d_loss=-10.637590,g_loss=-651.473511\n"
     ]
    }
   ],
   "source": [
    "gan=GAN(pokemon,20)\n",
    "gan.train(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from IPython.core.debugger import Tracer\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential,Model,load_model\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "gan=load_model('eevee2_model.h5', custom_objects={'wasserstein_loss': wasserstein_loss})\n",
    "#gan.summary()\n",
    "generator=gan.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c0501f7e224e2aa1a09738179f310f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(VBox(children=(VBox(children=(VBox(children=(VBox(children=(Box(children=(FloatSâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1dd0c77feb54b6c86e8f00d1b3ddc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from ipywidgets import FloatSlider\n",
    "x1=x2=x3=x4=x5=x6=x7=x8=x9=x10=x11=x12=x13=x14=x15=x16=x17=x18=x19=x20=x21=x22=x23=x24=x25=x26=x27=x28=x29=x30=0\n",
    "def showimg(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23,x24,x25):\n",
    "    input_vector=np.array([x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23,x24,x25])\n",
    "    input_vector=np.expand_dims(input_vector[0:15],axis=0)\n",
    "    img=generator.predict(input_vector)\n",
    "    img=np.reshape(img,(52,52,3))\n",
    "    img=(img+1)*127.5\n",
    "    plt.imshow(img.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "x1=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x2=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x3=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x4=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x5=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x6=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x7=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x8=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x9=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x10=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x11=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x12=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x13=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x14=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x15=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x16=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x17=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x18=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x19=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x20=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x21=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x22=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x23=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x24=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x25=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x26=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x27=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x28=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x29=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "x30=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
    "w=[x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23,x24,x25]\n",
    "from ipywidgets import Layout, Button, Box,VBox,HBox,interactive_output\n",
    "boxes=[]\n",
    "for i in range(7):\n",
    "    j=4*i+4\n",
    "    if j>25:\n",
    "        boxes.append(w[24])\n",
    "    else:\n",
    "        boxes.append(Box(w[j-4:j]))\n",
    "ui=boxes[0]\n",
    "for i in range(1,7):\n",
    "    ui=VBox([ui,boxes[i]])\n",
    "\n",
    "        #Box(children=w.children[j-4:j],layout=Layout(display='flex',flex_flow='row',align_items='stretch',border='solid',width='100%'))\n",
    "\n",
    "out=interactive_output(showimg,{'x1':x1\n",
    ",'x2':x2\n",
    ",'x3':x3\n",
    ",'x4':x4\n",
    ",'x5':x5\n",
    ",'x6':x6\n",
    ",'x7':x7\n",
    ",'x8':x8\n",
    ",'x9':x9\n",
    ",'x10':x10\n",
    ",'x11':x11\n",
    ",'x12':x12\n",
    ",'x13':x13\n",
    ",'x14':x14\n",
    ",'x15':x15\n",
    ",'x16':x16\n",
    ",'x17':x17\n",
    ",'x18':x18\n",
    ",'x19':x19\n",
    ",'x20':x20\n",
    ",'x21':x21\n",
    ",'x22':x22\n",
    ",'x23':x23\n",
    ",'x24':x24\n",
    ",'x25':x25})\n",
    "display(ui,out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x2=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x3=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x4=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x5=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x6=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x7=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x8=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x9=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x10=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x11=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x12=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x13=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x14=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x15=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x16=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x17=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x18=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x19=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x20=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x21=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x22=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x23=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x24=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x25=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x26=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x27=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x28=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x29=FloatSlider(min=-5.0, max=5.0, step=0.01)\n",
      "x30=FloatSlider(min=-5.0, max=5.0, step=0.01)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,31):\n",
    "    print(\"HBox\"%(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}