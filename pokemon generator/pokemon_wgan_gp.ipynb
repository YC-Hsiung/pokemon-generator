{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def loadpm():\n",
    "    pmimg=[]\n",
    "    idx=1\n",
    "    while True:\n",
    "        idx=str(idx)\n",
    "        imgpath='pics/full/40x40/poke'+idx+'.jpg'\n",
    "        \n",
    "        try:\n",
    "            img=plt.imread(imgpath)\n",
    "        except:\n",
    "            break\n",
    "        if(idx=='1'):\n",
    "            pmimg=img.reshape(1,img.shape[0], img.shape[1], 3)\n",
    "        else:\n",
    "            pmimg =np.vstack((pmimg,img.reshape(1,img.shape[0], img.shape[1], 3)))\n",
    "        idx=int(idx)\n",
    "        idx+=1\n",
    "    return pmimg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(840, 40, 40, 3)\n"
    }
   ],
   "source": [
    "pokemon=loadpm()\n",
    "pokemon=(pokemon-127.5)/127.5\n",
    "print((pokemon.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.core.debugger import Tracer\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout,Conv2D,MaxPooling2D,Conv2DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.merge import _Merge\n",
    "\n",
    "class Subtract(_Merge):\n",
    "    def _merge_function(self, inputs):\n",
    "        output = inputs[0]\n",
    "        for i in range(1, len(inputs)):\n",
    "            output = output-inputs[i]\n",
    "        return output\n",
    "class GradNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GradNorm, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        super(GradNorm, self).build(input_shapes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        target, wrt = inputs\n",
    "        grads = K.gradients(target, wrt)\n",
    "        assert len(grads) == 1\n",
    "        grad = grads[0]\n",
    "        return K.sqrt(K.sum(K.batch_flatten(K.square(grad)), axis=1, keepdims=True))\n",
    "\n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        return (input_shapes[1][0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self,gen_dim,output_size):\n",
    "        self.network=Sequential()\n",
    "        element=1\n",
    "        for i in output_size:\n",
    "            element*=i\n",
    "            \n",
    "        IsDense=False\n",
    "        if(IsDense):\n",
    "        #Dense\n",
    "            self.network.add(Dense(element//16,input_dim=gen_dim,activation='relu'))\n",
    "            self.network.add(Dense(element//4,activation='relu'))\n",
    "            self.network.add(Dense(element//4,activation='relu'))\n",
    "            self.network.add(Dense(element//1,activation='tanh'))\n",
    "            self.network.add(Reshape(output_size))\n",
    "        else:\n",
    "        #Convolution\n",
    "            self.network.add(Dense(element//16*256,input_dim=gen_dim))\n",
    "            self.network.add(LeakyReLU(0.2))\n",
    "            self.network.add(Reshape((output_size[0]//4,output_size[1]//4,output_size[2]*256)))\n",
    "            self.network.add(Conv2DTranspose(filters=256,kernel_size=(3,3),strides=2,padding='same')) \n",
    "            self.network.add(LeakyReLU(0.2)) \n",
    "            self.network.add(Conv2DTranspose(filters=256,kernel_size=(3,3),strides=2,padding='same'))\n",
    "            self.network.add(LeakyReLU(0.2))\n",
    "            self.network.add(Conv2DTranspose(filters=3,kernel_size=(5,5),padding='same',activation='tanh'))\n",
    "        self.network.summary()\n",
    "class Discriminator():\n",
    "    #Critic\n",
    "    def __init__(self,input_size):\n",
    "        self.network=Sequential()\n",
    "        element=1\n",
    "        for i in input_size:\n",
    "            element*=i\n",
    "\n",
    "        self.network.add(Conv2D(filters=256,kernel_size=(5,5),padding='same',input_shape=input_size))\n",
    "        self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add(Conv2D(filters=128,kernel_size=(3,3),padding='same'))\n",
    "        self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add(Conv2D(filters=128,kernel_size=(3,3),padding='same'))\n",
    "        self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add(Conv2D(filters=128,kernel_size=(3,3),padding='same'))\n",
    "        self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add((Flatten()))\n",
    "        self.network.add(Dense(1,activation='linear'))\n",
    "        \n",
    "        self.network.summary()\n",
    "        \n",
    "        \n",
    "        \n",
    "class GAN():\n",
    "    def __init__(self,trainingset,gen_dim):\n",
    "        self.trainshape=trainingset.shape\n",
    "        self.trainingset=trainingset\n",
    "        self.gen_dim=gen_dim\n",
    "        \n",
    "        self.n_discriminator = 10\n",
    "        \n",
    "        self._lambda = 10\n",
    "        optimizer = Adam(lr=0.0005,beta_1=0.2,beta_2=0.9)#RMSprop(lr=0.00005)\n",
    "        #gen_dis\n",
    "        self.generator=Generator(gen_dim,(trainingset.shape[1],trainingset.shape[2],trainingset.shape[3]))\n",
    "        self.discriminator=Discriminator((trainingset.shape[1],trainingset.shape[2],trainingset.shape[3]))\n",
    "        self.GAN_input=Input((gen_dim,))\n",
    "        self.GAN_output=self.discriminator.network(self.generator.network(self.GAN_input))\n",
    "        self.network=Model(self.GAN_input,self.GAN_output)\n",
    "        self.network.compile(loss=self.wasserstein_loss,optimizer=optimizer)\n",
    "        \n",
    "        #gradient\n",
    "        self.inputshape=self.trainshape[1:]\n",
    "        self.real_input,self.gen_input,self.mixed_input=Input(self.inputshape),Input(self.inputshape),Input(self.inputshape)\n",
    "        \n",
    "        self.sub=Subtract()([self.discriminator.network(self.gen_input),self.discriminator.network(self.real_input)])\n",
    "        self.grad_norm=GradNorm()([self.discriminator.network(self.mixed_input),self.mixed_input])\n",
    "        self.grad=Model([self.gen_input,self.real_input,self.mixed_input],[self.sub,self.grad_norm])\n",
    "        self.grad.compile(optimizer=optimizer,loss=[self.mean_loss,'MSE'],loss_weights=[1,self._lambda])\n",
    "        self.iter_had_trained=0\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    def mean_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_pred)\n",
    "    def train(self,iterations):\n",
    "        save_dir='output/all'\n",
    "        if os.path.isdir(save_dir)==False:\n",
    "            os.mkdir(save_dir)\n",
    "        #train discriminator\n",
    "        #self.start=0\n",
    "        self.batch_size=20\n",
    "        #self.more_to_stop=0\n",
    "        self.real_label=np.ones((self.batch_size, 1))\n",
    "        self.gen_label=-np.ones((self.batch_size, 1))\n",
    "        for step in range(iterations):\n",
    "        #train discriminator\n",
    "            for i in range(self.n_discriminator):\n",
    "            #prepare img\n",
    "                self.random_gen_vectors=np.random.normal(size=(self.batch_size,self.gen_dim))\n",
    "                self.gen_img=self.generator.network.predict(self.random_gen_vectors)\n",
    "                self.epsilon=np.random.uniform(0,1,size=(self.batch_size,1,1,1))\n",
    "                self.idx=np.random.randint(0,self.trainingset.shape[0],self.batch_size)\n",
    "                self.real_img=self.trainingset[self.idx]\n",
    "                self.mixed=self.epsilon*self.real_img+(1-self.epsilon)*self.gen_img\n",
    "                \n",
    "        \n",
    "                #self.labels -= 0.1 * np.random.rand(self.labels.shape[0],self.labels.shape[1])\n",
    "                self.discriminator.network.trainable = True\n",
    "                self.d_loss = self.grad.train_on_batch([self.gen_img,self.real_img,self.mixed],[np.ones((self.batch_size,1)),np.ones((self.batch_size,1))])\n",
    "                \n",
    "                \n",
    "        #train generator\n",
    "            self.discriminator.network.trainable = False\n",
    "            self.random_gen_vector=np.random.normal(size=(self.batch_size,self.gen_dim))\n",
    "            self.g_loss=self.network.train_on_batch(self.random_gen_vector,self.gen_label)\n",
    "            print('iter:%d,d_loss=%f,g_loss=%f'%(step,self.d_loss[0],self.g_loss))\n",
    "            if self.iter_had_trained % 100==0:\n",
    "                #save image\n",
    "                random_vector=np.random.normal(size=(25,self.gen_dim))\n",
    "                images=self.generator.network.predict(random_vector)\n",
    "                images=(images+1)*127.5\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                for i in range(images.shape[0]):\n",
    "                    plt.subplot(5,5,i+1)\n",
    "                    image = images[i, :, :, :]\n",
    "                    image = np.reshape(image,(self.trainshape[1:]))\n",
    "                    plt.imshow(image.astype(np.uint8))\n",
    "                    plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\"%s/poke_%d.png\" % (save_dir,self.iter_had_trained))\n",
    "                if self.iter_had_trained%5000==0:\n",
    "                    gan.network.save('%s/con_leaky_all%d.h5' % (save_dir,self.iter_had_trained))\n",
    "                plt.close('all')\n",
    "            self.iter_had_trained+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_29 (Dense)             (None, 76800)             1996800   \n_________________________________________________________________\nleaky_re_lu_99 (LeakyReLU)   (None, 76800)             0         \n_________________________________________________________________\nreshape_15 (Reshape)         (None, 10, 10, 768)       0         \n_________________________________________________________________\nconv2d_transpose_43 (Conv2DT (None, 20, 20, 256)       1769728   \n_________________________________________________________________\nleaky_re_lu_100 (LeakyReLU)  (None, 20, 20, 256)       0         \n_________________________________________________________________\nconv2d_transpose_44 (Conv2DT (None, 40, 40, 256)       590080    \n_________________________________________________________________\nleaky_re_lu_101 (LeakyReLU)  (None, 40, 40, 256)       0         \n_________________________________________________________________\nconv2d_transpose_45 (Conv2DT (None, 40, 40, 3)         19203     \n=================================================================\nTotal params: 4,375,811\nTrainable params: 4,375,811\nNon-trainable params: 0\n_________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_57 (Conv2D)           (None, 40, 40, 256)       19456     \n_________________________________________________________________\nleaky_re_lu_102 (LeakyReLU)  (None, 40, 40, 256)       0         \n_________________________________________________________________\nconv2d_58 (Conv2D)           (None, 40, 40, 128)       295040    \n_________________________________________________________________\nleaky_re_lu_103 (LeakyReLU)  (None, 40, 40, 128)       0         \n_________________________________________________________________\nconv2d_59 (Conv2D)           (None, 40, 40, 128)       147584    \n_________________________________________________________________\nleaky_re_lu_104 (LeakyReLU)  (None, 40, 40, 128)       0         \n_________________________________________________________________\nconv2d_60 (Conv2D)           (None, 40, 40, 128)       147584    \n_________________________________________________________________\nleaky_re_lu_105 (LeakyReLU)  (None, 40, 40, 128)       0         \n_________________________________________________________________\nflatten_15 (Flatten)         (None, 204800)            0         \n_________________________________________________________________\ndense_30 (Dense)             (None, 1)                 204801    \n=================================================================\nTotal params: 814,465\nTrainable params: 814,465\nNon-trainable params: 0\n_________________________________________________________________\niter:0,d_loss=-141.177155,g_loss=0.900797\niter:1,d_loss=-125.053459,g_loss=-19.808693\niter:2,d_loss=-60.927288,g_loss=-48.692799\niter:3,d_loss=-13.420622,g_loss=-71.000435\niter:4,d_loss=-29.885466,g_loss=-4.875536\niter:5,d_loss=-47.096405,g_loss=35.522789\niter:6,d_loss=-45.581791,g_loss=42.732018\niter:7,d_loss=-36.144341,g_loss=-15.362247\niter:8,d_loss=-27.750242,g_loss=-7.224883\niter:9,d_loss=-20.417713,g_loss=-68.060608\niter:10,d_loss=-32.334496,g_loss=2.800149\niter:11,d_loss=-31.629219,g_loss=-53.863350\niter:12,d_loss=-28.102453,g_loss=-86.320717\niter:13,d_loss=-24.786123,g_loss=-41.535988\niter:14,d_loss=-26.928169,g_loss=-60.370094\niter:15,d_loss=-22.615593,g_loss=-30.545059\niter:16,d_loss=-29.452869,g_loss=-25.806961\niter:17,d_loss=-29.191380,g_loss=-48.063583\niter:18,d_loss=-22.068893,g_loss=-46.623035\niter:19,d_loss=-18.631002,g_loss=-34.758015\niter:20,d_loss=-24.128645,g_loss=-24.649307\niter:21,d_loss=-27.700502,g_loss=-38.015411\niter:22,d_loss=-27.834711,g_loss=-35.414131\niter:23,d_loss=-8.214884,g_loss=-27.356287\niter:24,d_loss=-20.499264,g_loss=-34.596760\niter:25,d_loss=-24.444305,g_loss=-40.400208\niter:26,d_loss=-23.147886,g_loss=-25.574221\niter:27,d_loss=-21.666920,g_loss=-50.761578\niter:28,d_loss=-23.368322,g_loss=-6.852872\niter:29,d_loss=-18.860039,g_loss=-35.935341\niter:30,d_loss=-19.922638,g_loss=-29.057755\niter:31,d_loss=-20.218681,g_loss=-37.342743\niter:32,d_loss=-20.824543,g_loss=-36.575500\niter:33,d_loss=-17.859800,g_loss=-9.120671\niter:34,d_loss=-16.859306,g_loss=-29.712673\niter:35,d_loss=-15.347408,g_loss=-31.017023\niter:36,d_loss=-16.795925,g_loss=-31.186146\niter:37,d_loss=-19.935001,g_loss=-1.535587\niter:38,d_loss=-9.759056,g_loss=-84.232201\niter:39,d_loss=-19.180084,g_loss=-4.918554\niter:40,d_loss=-16.120590,g_loss=-35.937614\niter:41,d_loss=-12.175541,g_loss=-56.298393\niter:42,d_loss=-18.073168,g_loss=-39.238548\niter:43,d_loss=-15.008285,g_loss=-43.703777\niter:44,d_loss=-15.121765,g_loss=-43.689514\niter:45,d_loss=-13.797525,g_loss=-25.905542\niter:46,d_loss=-14.021738,g_loss=-38.968990\niter:47,d_loss=-11.340364,g_loss=-55.927044\niter:48,d_loss=-13.780212,g_loss=-20.127804\niter:49,d_loss=-12.858660,g_loss=-31.092823\niter:50,d_loss=-10.796942,g_loss=-12.539521\niter:51,d_loss=-17.616713,g_loss=4.162145\niter:52,d_loss=-14.107515,g_loss=-32.750633\niter:53,d_loss=-14.983023,g_loss=-28.801550\niter:54,d_loss=-16.636026,g_loss=-17.135843\niter:55,d_loss=-15.009768,g_loss=-34.789082\niter:56,d_loss=-15.780003,g_loss=-31.081549\niter:57,d_loss=-12.685524,g_loss=4.707452\niter:58,d_loss=-14.584618,g_loss=-14.089406\niter:59,d_loss=-13.387665,g_loss=-34.864578\niter:60,d_loss=-14.134632,g_loss=-22.938786\niter:61,d_loss=-13.052333,g_loss=-17.352118\niter:62,d_loss=-19.114105,g_loss=-4.240133\niter:63,d_loss=-12.664892,g_loss=-29.822636\niter:64,d_loss=-12.009404,g_loss=-35.850002\niter:65,d_loss=-13.007642,g_loss=-30.357208\niter:66,d_loss=-11.884718,g_loss=-37.423695\niter:67,d_loss=-13.056749,g_loss=-24.002268\niter:68,d_loss=-13.074709,g_loss=-31.746435\niter:69,d_loss=-6.801775,g_loss=-57.463970\niter:70,d_loss=-15.940715,g_loss=-48.957855\niter:71,d_loss=-14.217911,g_loss=-27.324097\niter:72,d_loss=-12.721862,g_loss=-55.947350\niter:73,d_loss=-13.627913,g_loss=-2.526748\niter:74,d_loss=-15.746672,g_loss=-55.733875\niter:75,d_loss=-10.061442,g_loss=-39.763546\niter:76,d_loss=-13.340780,g_loss=-42.195660\niter:77,d_loss=-10.919897,g_loss=-39.261738\niter:78,d_loss=-11.317723,g_loss=-27.608242\niter:79,d_loss=-10.410525,g_loss=-36.346771\niter:80,d_loss=-15.972326,g_loss=-75.856941\niter:81,d_loss=-12.241546,g_loss=-41.338230\niter:82,d_loss=-10.016711,g_loss=-25.569717\niter:83,d_loss=-14.032963,g_loss=-35.712261\niter:84,d_loss=-14.837576,g_loss=-40.010334\niter:85,d_loss=-13.464943,g_loss=-39.708244\niter:86,d_loss=-7.776494,g_loss=-40.972923\niter:87,d_loss=-9.465655,g_loss=-28.326160\niter:88,d_loss=-9.862809,g_loss=-49.589851\niter:89,d_loss=-9.810302,g_loss=-47.051010\niter:90,d_loss=-8.974188,g_loss=-61.185112\niter:91,d_loss=-7.528470,g_loss=-28.204021\niter:92,d_loss=-7.545912,g_loss=-55.600666\niter:93,d_loss=-11.869821,g_loss=-17.962379\niter:94,d_loss=-11.216322,g_loss=-35.140789\niter:95,d_loss=-10.357224,g_loss=-41.622307\niter:96,d_loss=-15.375207,g_loss=-111.346779\niter:97,d_loss=-15.717195,g_loss=-13.784983\niter:98,d_loss=-7.790652,g_loss=-72.297012\niter:99,d_loss=-8.322016,g_loss=-66.620071\niter:100,d_loss=-7.552241,g_loss=-82.390923\niter:101,d_loss=-10.837049,g_loss=-64.026817\niter:102,d_loss=-10.061864,g_loss=-59.378887\niter:103,d_loss=-10.650491,g_loss=-65.026489\niter:104,d_loss=-7.314445,g_loss=-55.568287\niter:105,d_loss=-8.861937,g_loss=-65.209373\niter:106,d_loss=-11.544125,g_loss=-62.059715\niter:107,d_loss=-8.078416,g_loss=-31.186245\niter:108,d_loss=-9.334792,g_loss=-43.895527\niter:109,d_loss=-10.559444,g_loss=-73.345726\niter:110,d_loss=-10.082763,g_loss=-15.234637\niter:111,d_loss=-7.183821,g_loss=-57.587952\niter:112,d_loss=-10.309310,g_loss=-45.360859\niter:113,d_loss=-8.833822,g_loss=-54.121998\niter:114,d_loss=-9.733194,g_loss=-48.204700\niter:115,d_loss=-9.051339,g_loss=-45.521168\niter:116,d_loss=-10.728798,g_loss=-52.864330\niter:117,d_loss=-9.151934,g_loss=-55.477886\niter:118,d_loss=-8.155719,g_loss=-48.680927\niter:119,d_loss=-10.046613,g_loss=-58.079052\niter:120,d_loss=-9.935976,g_loss=-60.304737\niter:121,d_loss=-10.142099,g_loss=6.196996\niter:122,d_loss=-10.394621,g_loss=-45.706245\niter:123,d_loss=-7.526132,g_loss=-31.013803\niter:124,d_loss=-5.530289,g_loss=-43.506584\niter:125,d_loss=-7.894099,g_loss=-39.126278\niter:126,d_loss=-9.059398,g_loss=-26.403692\niter:127,d_loss=-10.665670,g_loss=-63.455944\niter:128,d_loss=-10.661347,g_loss=-45.442463\niter:129,d_loss=-8.666340,g_loss=-51.724926\niter:130,d_loss=-7.046150,g_loss=-50.674488\niter:131,d_loss=-8.210224,g_loss=-54.215721\niter:132,d_loss=-10.174540,g_loss=-45.212132\niter:133,d_loss=-10.283158,g_loss=-68.129402\niter:134,d_loss=-11.467766,g_loss=-37.282200\niter:135,d_loss=-14.186486,g_loss=-72.388664\niter:136,d_loss=-7.961165,g_loss=-19.301409\niter:137,d_loss=-7.179805,g_loss=-71.869179\niter:138,d_loss=-7.223673,g_loss=-60.096966\niter:139,d_loss=-8.275784,g_loss=-74.552536\niter:140,d_loss=-10.282794,g_loss=-45.200951\niter:141,d_loss=-6.687443,g_loss=-60.323875\niter:142,d_loss=-9.972324,g_loss=-58.226662\niter:143,d_loss=-9.385769,g_loss=-74.459465\niter:144,d_loss=-8.591785,g_loss=-57.847984\niter:145,d_loss=-7.966576,g_loss=-52.589447\niter:146,d_loss=-8.328190,g_loss=-58.584755\niter:147,d_loss=-9.262798,g_loss=-63.156128\niter:148,d_loss=-8.906046,g_loss=-60.320507\niter:149,d_loss=-9.129975,g_loss=-46.536549\niter:150,d_loss=-10.735878,g_loss=-70.312370\niter:151,d_loss=-9.487033,g_loss=-45.159039\niter:152,d_loss=-7.837465,g_loss=-49.671776\niter:153,d_loss=-8.628256,g_loss=-53.900352\niter:154,d_loss=-8.375893,g_loss=-72.508774\niter:155,d_loss=-7.389827,g_loss=-58.106781\niter:156,d_loss=-8.203406,g_loss=-72.869583\niter:157,d_loss=-7.288494,g_loss=-53.932373\niter:158,d_loss=-3.679818,g_loss=-67.169373\niter:159,d_loss=-8.138363,g_loss=-65.597412\niter:160,d_loss=-7.268793,g_loss=-65.452049\niter:161,d_loss=-8.176771,g_loss=-70.184792\niter:162,d_loss=-9.543184,g_loss=-68.770813\niter:163,d_loss=-8.087413,g_loss=-69.385941\niter:164,d_loss=-6.935396,g_loss=-49.789528\niter:165,d_loss=-10.716000,g_loss=-61.810188\niter:166,d_loss=-9.818086,g_loss=-51.728722\niter:167,d_loss=-8.386048,g_loss=-59.116302\niter:168,d_loss=-7.448144,g_loss=-49.186565\niter:169,d_loss=-6.998109,g_loss=-63.183277\niter:170,d_loss=-12.272960,g_loss=-57.700451\niter:171,d_loss=-9.827995,g_loss=-55.544544\niter:172,d_loss=-8.700766,g_loss=-49.288395\niter:173,d_loss=-8.593376,g_loss=-59.333111\niter:174,d_loss=-2.635885,g_loss=-60.569813\niter:175,d_loss=-8.524868,g_loss=-70.934456\niter:176,d_loss=-7.116978,g_loss=-76.016525\niter:177,d_loss=-8.128426,g_loss=-54.871284\niter:178,d_loss=-8.657563,g_loss=-71.242775\niter:179,d_loss=-7.259675,g_loss=-64.621246\niter:180,d_loss=-7.729737,g_loss=-61.477367\niter:181,d_loss=-13.275530,g_loss=-56.602638\niter:182,d_loss=-9.499726,g_loss=-49.780525\niter:183,d_loss=-9.183496,g_loss=-66.832237\niter:184,d_loss=-13.285145,g_loss=-39.929413\niter:185,d_loss=-8.338152,g_loss=-85.102066\niter:186,d_loss=-8.342041,g_loss=-84.818230\niter:187,d_loss=-8.267545,g_loss=-78.068161\niter:188,d_loss=-3.251927,g_loss=-70.800766\niter:189,d_loss=-8.383059,g_loss=-64.357689\niter:190,d_loss=-9.475952,g_loss=-83.759789\niter:191,d_loss=-14.012657,g_loss=-58.416271\niter:192,d_loss=-12.034456,g_loss=-22.933130\niter:193,d_loss=-8.551626,g_loss=-69.473244\niter:194,d_loss=-8.895091,g_loss=-79.156601\niter:195,d_loss=-10.801422,g_loss=-76.914246\niter:196,d_loss=-7.639524,g_loss=-68.430908\niter:197,d_loss=-10.164254,g_loss=-67.149734\niter:198,d_loss=-8.766743,g_loss=-80.617065\niter:199,d_loss=-9.238350,g_loss=-71.875198\niter:200,d_loss=-7.998441,g_loss=-63.839008\niter:201,d_loss=-7.423453,g_loss=-61.935944\niter:202,d_loss=-9.000485,g_loss=-77.412186\niter:203,d_loss=-7.419579,g_loss=-68.800865\niter:204,d_loss=-6.714885,g_loss=-75.807426\niter:205,d_loss=-8.774657,g_loss=-89.236908\niter:206,d_loss=-15.104675,g_loss=-77.457306\niter:207,d_loss=-9.057144,g_loss=-24.554447\niter:208,d_loss=-12.438883,g_loss=-54.277374\niter:209,d_loss=-3.279188,g_loss=-29.540625\niter:210,d_loss=-7.903929,g_loss=-8.774325\niter:211,d_loss=-9.307775,g_loss=-83.338486\niter:212,d_loss=-9.632093,g_loss=-108.425659\niter:213,d_loss=-7.320149,g_loss=-56.262825\niter:214,d_loss=-7.497207,g_loss=-55.508965\niter:215,d_loss=-7.535974,g_loss=-71.960449\niter:216,d_loss=-8.948822,g_loss=-79.604004\niter:217,d_loss=-13.776245,g_loss=-95.488075\niter:218,d_loss=-7.607690,g_loss=-51.132996\niter:219,d_loss=-7.554770,g_loss=-81.073410\niter:220,d_loss=-9.082883,g_loss=-84.563881\niter:221,d_loss=-8.624012,g_loss=-63.797630\niter:222,d_loss=-5.818171,g_loss=-58.677086\niter:223,d_loss=-8.779528,g_loss=-87.911606\niter:224,d_loss=-5.090613,g_loss=-99.480324\niter:225,d_loss=-6.449376,g_loss=-80.364159\niter:226,d_loss=-8.294534,g_loss=-76.827293\niter:227,d_loss=-7.468098,g_loss=-2.687352\niter:228,d_loss=-9.419591,g_loss=-64.294479\niter:229,d_loss=-8.927774,g_loss=-55.047688\niter:230,d_loss=-7.367544,g_loss=-86.770927\niter:231,d_loss=-6.365009,g_loss=-97.036179\niter:232,d_loss=-3.052611,g_loss=-40.600243\niter:233,d_loss=-9.106073,g_loss=-94.013992\niter:234,d_loss=-7.814706,g_loss=-61.700844\niter:235,d_loss=-7.250135,g_loss=-72.980453\niter:236,d_loss=-6.941032,g_loss=-81.886826\niter:237,d_loss=-8.405035,g_loss=-93.878555\niter:238,d_loss=-7.496577,g_loss=-46.272949\niter:239,d_loss=-8.636249,g_loss=-68.792686\niter:240,d_loss=-8.617208,g_loss=-77.025826\niter:241,d_loss=-7.298026,g_loss=-90.172592\niter:242,d_loss=-8.397352,g_loss=-61.309948\n"
    }
   ],
   "source": [
    "gan=GAN(pokemon,25)\n",
    "gan.train(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.debugger import Tracer\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential,Model,load_model\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "gan=load_model('eevee2_model.h5', custom_objects={'wasserstein_loss': wasserstein_loss})\n",
    "#gan.summary()\n",
    "generator=gan.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vector=np.random.normal(size=(10,20))\n",
    "random_number=np.random.randint(0,pokemon.shape[0],size=10)\n",
    "images=self.generator.network.predict(random_vector)\n",
    "images=(images+1)*127.5\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in random_number:\n",
    "    plt.subplot(4,5,i+1)\n",
    "    image = pokemon[i, :, :, :]\n",
    "    image = np.reshape(image,(pokemon.shape[1:]))\n",
    "    image=(image+1)*127.5\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "for i in range(images.shape[0]):\n",
    "    plt.subplot(4,5,i+11)\n",
    "    image = images[i, :, :, :]\n",
    "    image = np.reshape(image,(pokemon.shape[1:]))\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n"
   ]
  }
 ]
}