{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def loadpm():\n",
    "    idx=1\n",
    "    idx=str(idx)\n",
    "    imgpath='pics/type/pichu/poke'+idx+'.jpg'\n",
    "    try:\n",
    "        pmimg=plt.imread(imgpath)\n",
    "        pmimg=pmimg.reshape(1,pmimg.shape[0], pmimg.shape[1], 3)\n",
    "    except:\n",
    "        return\n",
    "    idx=int(idx)\n",
    "    idx+=1\n",
    "    while True:\n",
    "        idx=str(idx)\n",
    "        imgpath='pics/type/pichu/poke'+idx+'.jpg'\n",
    "        #imgpath='pics/type/grass/40x40/poke'+idx+'.jpg'\n",
    "        try:\n",
    "            img=plt.imread(imgpath)\n",
    "        except:\n",
    "            break\n",
    "        pmimg =np.vstack((pmimg,img.reshape(1,img.shape[0], img.shape[1], 3)))\n",
    "        idx=int(idx)\n",
    "        idx+=1\n",
    "    return pmimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 40, 40, 3)\n"
     ]
    }
   ],
   "source": [
    "pokemon=loadpm()\n",
    "pokemon=(pokemon-127.5)/127.5\n",
    "print((pokemon.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.core.debugger import Tracer\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout,Conv2D,MaxPooling2D,Conv2DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 614400)            12902400  \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 40, 40, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 40, 40, 256)       2457856   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 40, 40, 3)         6915      \n",
      "=================================================================\n",
      "Total params: 15,959,299\n",
      "Trainable params: 15,958,275\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 40, 40, 256)       19456     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 409600)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                8192020   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 9,394,729\n",
      "Trainable params: 9,393,193\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0,d_loss=3.744668,g_loss=8.768312\n",
      "iter:1,d_loss=6.815049,g_loss=5.579835\n",
      "iter:2,d_loss=7.218001,g_loss=7.971193\n",
      "iter:3,d_loss=6.017929,g_loss=5.579835\n",
      "iter:4,d_loss=5.606191,g_loss=7.174073\n",
      "iter:5,d_loss=3.201655,g_loss=7.971193\n",
      "iter:6,d_loss=3.201655,g_loss=7.174073\n",
      "iter:7,d_loss=7.612167,g_loss=7.971193\n",
      "iter:8,d_loss=5.606191,g_loss=7.971193\n",
      "iter:9,d_loss=5.212024,g_loss=6.376954\n",
      "iter:10,d_loss=4.804679,g_loss=7.174074\n",
      "iter:11,d_loss=7.620954,g_loss=7.174074\n",
      "iter:12,d_loss=2.798703,g_loss=7.971193\n",
      "iter:13,d_loss=4.406119,g_loss=7.971193\n",
      "iter:14,d_loss=4.406119,g_loss=6.376954\n",
      "iter:15,d_loss=6.416489,g_loss=7.174073\n",
      "iter:16,d_loss=4.813465,g_loss=8.768312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2e04c34261f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpokemon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-2e04c34261f1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, iterations)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;31m#self.labels -= 0.05 * np.random.rand(self.labels.shape[0],self.labels.shape[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombined_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\a1091\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Generator():\n",
    "    def __init__(self,gen_dim,output_size):\n",
    "        self.network=Sequential()\n",
    "        element=1\n",
    "        for i in output_size:\n",
    "            element*=i\n",
    "        \n",
    "        self.network.add(Dense(element//1*128,input_dim=gen_dim,activation='relu'))\n",
    "        self.network.add(Reshape((output_size[0]//1,output_size[1]//1,output_size[2]*128)))\n",
    "        '''self.network.add(BatchNormalization(momentum=0.8))\n",
    "        #self.network.add(LeakyReLU(0.2))\n",
    "        \n",
    "        self.network.add(Dense(element//2,activation='relu'))\n",
    "        self.network.add(BatchNormalization(momentum=0.8))\n",
    "        self.network.add(Dense(element,activation='tanh'))\n",
    "        \n",
    "        self.network.add(Reshape(output_size))'''\n",
    "        \n",
    "        self.network.add(Conv2DTranspose(filters=256,kernel_size=(5,5),strides=1,padding='same'))\n",
    "        self.network.add(BatchNormalization(momentum=0.8))\n",
    "        self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add(Conv2DTranspose(filters=256,kernel_size=(3,3),strides=1,padding='same'))\n",
    "        self.network.add(BatchNormalization(momentum=0.8))\n",
    "        self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add(Conv2DTranspose(filters=3,kernel_size=(3,3),padding='same',activation='tanh'))\n",
    "        \n",
    "        self.network.summary()\n",
    "class Discriminator():\n",
    "    def __init__(self,input_size):\n",
    "        self.network=Sequential()\n",
    "        element=1\n",
    "        for i in input_size:\n",
    "            element*=i\n",
    "        self.network.add(Conv2D(filters=256,kernel_size=(5,5),padding='same',input_shape=input_size))\n",
    "        self.network.add(BatchNormalization(momentum=0.8))\n",
    "        #self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add(Conv2D(filters=256,kernel_size=(3,3),padding='same'))\n",
    "        self.network.add(BatchNormalization(momentum=0.8))\n",
    "        #self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add(Conv2D(filters=256,kernel_size=(3,3),padding='same'))\n",
    "        self.network.add(BatchNormalization(momentum=0.8))\n",
    "        #self.network.add(LeakyReLU(0.2))\n",
    "        self.network.add((Flatten()))\n",
    "        #self.network.add(Dropout(0.25))\n",
    "        self.network.add(Dense(20))\n",
    "       \n",
    "        self.network.add(Dense(1))\n",
    "        optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8)\n",
    "        self.network.compile(optimizer='SGD', loss='binary_crossentropy')\n",
    "        self.network.summary()\n",
    "class GAN():\n",
    "    def __init__(self,trainingset,gen_dim):\n",
    "        self.trainshape=trainingset.shape\n",
    "        self.trainingset=trainingset\n",
    "        self.gen_dim=gen_dim\n",
    "        self.generator=Generator(gen_dim,(trainingset.shape[1],trainingset.shape[2],trainingset.shape[3]))\n",
    "        self.discriminator=Discriminator((trainingset.shape[1],trainingset.shape[2],trainingset.shape[3]))\n",
    "        self.discriminator.network.trainable = False\n",
    "        self.GAN_input=Input((gen_dim,))\n",
    "        self.GAN_output=self.discriminator.network(self.generator.network(self.GAN_input))\n",
    "        self.network=Model(self.GAN_input,self.GAN_output)\n",
    "        optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8)\n",
    "        self.network.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "    def train(self,iterations):\n",
    "        #train discriminator\n",
    "        self.start=0\n",
    "        self.batch_size=20\n",
    "        self.more_to_stop=0\n",
    "        for step in range(iterations):\n",
    "        #prepare img\n",
    "            self.random_gen_vectors=np.random.normal(size=(self.batch_size,self.gen_dim))\n",
    "            self.generated_img=self.generator.network.predict(self.random_gen_vectors)\n",
    "            self.stop=self.start+self.batch_size\n",
    "            if self.stop>self.trainshape[0]:\n",
    "                self.more_to_stop=int(self.stop-self.trainshape[0])\n",
    "                self.stop=self.trainshape[0]\n",
    "            self.real_img=self.trainingset[self.start:self.stop]\n",
    "            if self.more_to_stop!=0:\n",
    "                self.real_img=np.concatenate([self.real_img,self.trainingset[0:self.more_to_stop]])\n",
    "                self.start=self.more_to_stop\n",
    "                self.more_to_stop=0\n",
    "            self.combined_img = np.concatenate([self.generated_img,self.real_img])\n",
    "        #label img\n",
    "            self.labels=np.concatenate([np.ones((self.batch_size, 1)),np.zeros((self.batch_size, 1))])\n",
    "            #self.labels -= 0.05 * np.random.rand(self.labels.shape[0],self.labels.shape[1])\n",
    "            self.labels=abs(self.labels)\n",
    "            self.d_loss = self.discriminator.network.train_on_batch(self.combined_img,self.labels)\n",
    "            self.start+=self.batch_size\n",
    "            if(self.start>self.trainshape[0]-1):\n",
    "                self.start=0\n",
    "        #train generator\n",
    "            self.mislabeled=np.zeros((self.batch_size,1))\n",
    "            self.random_gen_vector=np.random.normal(size=(self.batch_size,self.gen_dim))\n",
    "            self.g_loss=self.network.train_on_batch(self.random_gen_vector,self.mislabeled)\n",
    "            print('iter:%d,d_loss=%f,g_loss=%f'%(step,self.d_loss,self.g_loss))\n",
    "            if step%50==0:\n",
    "                #save image\n",
    "                random_vector=np.random.normal(size=(25,self.gen_dim))\n",
    "                images=self.generator.network.predict(random_vector)\n",
    "                images=(images)*127.5+127.5\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                for i in range(images.shape[0]):\n",
    "                    plt.subplot(5,5,i+1)\n",
    "                    image = images[i, :, :, :]\n",
    "                    image = np.reshape(image,(self.trainshape[1:]))\n",
    "                    plt.imshow(image.astype(np.uint8))\n",
    "                    plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\"output/poke_%d.png\" % step)\n",
    "                plt.close('all')\n",
    "                    \n",
    "gan=GAN(pokemon,20)\n",
    "gan.train(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.network.save_weights('_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#gan.network.save('grass_model.h5') \n",
    "#gan.network=load_model('weights/water_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.network.summary()\n",
    "gan.generator.network=gan.network.layers[1]\n",
    "gan.discriminator.network=gan.network.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vector=np.random.normal(size=(25,25))\n",
    "images=gan.generator.network.predict(random_vector)\n",
    "images=(images+1)*127.5\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(images.shape[0]):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    image = images[i, :, :, :]\n",
    "    image = np.reshape(image,((40,40,3)))\n",
    "    plt.imshow(image.astype(np.uint8),cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"output/poke_%d.png\" % step)\n",
    "#plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
